# TOKYO-OLYMPIC-AZURE-DATA-ENGINEERING-PROJECT-
Analyze Olympic data using various tools and technologies, including Azure Data Factory, Data Lake Gen 2, Synapse Analytics, and Azure Databricks.

Objective: Migrate and analyze Tokyo Olympic data using Azure Data Engineering tools.
Data Source: On-premises SQL database containing Olympic data.
Destination: Azure Storage Account for scalable, cloud-based storage.
Tools Used: Azure Storage Account, Azure Data Factory, Self-hosted Integration Runtime.
Steps:
Create Azure Storage Account: Set up storage in the Azure portal.
Set Up Azure Data Factory: Deploy Data Factory for data orchestration.
Configure Integration Runtime: Install and register a Self-hosted Integration Runtime for connecting on-prem SQL.
Create Data Pipeline: Develop a pipeline in Data Factory to copy data from on-prem SQL to Azure Storage.
Schedule Pipeline: Use triggers to automate and schedule the data transfer process.
Outcome: Efficient, automated migration of Olympic data to Azure for further analysis and reporting.





